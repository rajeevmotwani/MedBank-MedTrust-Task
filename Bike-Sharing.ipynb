{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook about bike sharing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Description:\n",
    "### make an explorative data analysis and build a prediction model for the hourly utilization “cnt” of this data set: \n",
    "### https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description:\n",
    "    Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv\n",
    "\n",
    "- instant: record index\n",
    "- dteday : date\n",
    "- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "- yr : year (0: 2011, 1:2012)\n",
    "- mnth : month ( 1 to 12)\n",
    "- hr : hour (0 to 23)\n",
    "- holiday : weather day is holiday or not (extracted from [Web Link])\n",
    "- weekday : day of the week\n",
    "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "+ weathersit : \n",
    "- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n",
    "- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
    "- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "- casual: count of casual users\n",
    "- registered: count of registered users\n",
    "- cnt: count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_df(filepath):\n",
    "    '''\n",
    "    load the dataset into the system using pandas.read_csv function\n",
    "    \n",
    "    Parameters:\n",
    "    filepath: Path to the dataset\n",
    "    \n",
    "    Returns:\n",
    "    df: Generated dataframe\n",
    "    '''\n",
    "    df=pd.read_csv(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    '''Preparation of the dataset into train and test data to used in the models\n",
    "    \n",
    "        Parameters:\n",
    "        df: dataframe name\n",
    "\n",
    "        Returns:\n",
    "        X_train,X_test,y_train,y_test: train and test dataset\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #check for missing values:\n",
    "    assert pd.notnull(df).all().all()\n",
    "    \n",
    "    #feature generation from date:\n",
    "    '''We already have features like Month, Year and dayofweek as column of the dataframe.'''\n",
    "    df['day'] = pd.DatetimeIndex(df['dteday']).day\n",
    "    \n",
    "    # Normalization of the right skewed distribution target variable:\n",
    "    print('Normalizing count column of df')\n",
    "    df['cnt'] = np.log(df['cnt'])\n",
    "    print('Normalization done')\n",
    "    \n",
    "    # Drop leakage columns as they generate too good to be true prediction score for the models:\n",
    "    df = df.drop(['dteday', 'atemp', 'casual', 'registered'],axis=1)\n",
    "    \n",
    "    #df[['cnt','temp','hum','windspeed']] = df[['cnt','temp','hum','windspeed']].apply(lambda x: x/x.max(), axis=0)\n",
    "    '''columns = ['season', 'mnth','hr','weekday','weathersit', 'day']\n",
    "    for col in columns:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "    df = pd.concat([df, dummies], axis=1)'''\n",
    "    \n",
    "    #Divide dataframe into trainset and testset\n",
    "    X = df.drop(['cnt'], axis=1)\n",
    "    y = df['cnt']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(X_train, X_test, y_train, y_test, regressor):\n",
    "    \n",
    "    # The parameters of the regressors are generated after applying GridSearchCV\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    regressor.fit(X = X_train, y = np.log1p(y_train))\n",
    "    y_preds = regressor.predict(X_test)\n",
    "    score = regressor.score(X_test,np.log1p(y_test))\n",
    "    mae = metrics.mean_absolute_error(y_test, np.exp(y_preds))\n",
    "    \n",
    "    return score, mae, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(filepath):\n",
    "    \"\"\" load dataset, build feature set, and do learning\n",
    "        Parameters\n",
    "        ----------\n",
    "        fn: file name of dataset\n",
    "        features: a list of list, each of which is a feature list for different models\n",
    "        type: str for indicating feature set\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        predictions and feature-engineered dataset are saved to files\n",
    "    \"\"\"\n",
    "    df = load_df(filepath)\n",
    "    print(df.head())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data_prep(df)\n",
    "    X_test.to_csv('E:\\\\Personal\\\\tasks\\\\Xtest.csv',index=False)\n",
    "    y_test.to_csv('E:\\\\Personal\\\\tasks\\\\Ytest.csv',index=False)    \n",
    "    for i, regressor in enumerate((\n",
    "        RandomForestRegressor(n_estimators=100, max_depth=20),\n",
    "        GradientBoostingRegressor(n_estimators=150, max_depth=10, min_samples_leaf=20, learning_rate=0.1),\n",
    "        SVR(kernel='rbf', C=50)\n",
    "        )):\n",
    "        score, mae, y_preds = generate_model(X_train, X_test, y_train, y_test, regressor)\n",
    "        rname = str(regressor).split('(')[0]\n",
    "        #print(rname, y_preds)\n",
    "        print(rname, score, mae)\n",
    "        results = pd.DataFrame({'hr': X_test.loc[:,'hr'], 'cnt': y_test, 'prediction': np.exp(y_preds)})\n",
    "        results.to_csv('E:\\\\Personal\\\\tasks\\\\results.csv', index = False, columns=['hr', 'cnt', 'prediction'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n",
      "Normalizing count column of df\n",
      "Normalization done\n",
      "RandomForestRegressor 0.89332532398 0.992399230036\n",
      "GradientBoostingRegressor 0.903705111806 0.995852119665\n",
      "SVR 0.631264103503 0.776847609117\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_model(filepath='E:\\\\Personal\\\\tasks\\\\hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
